{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZHR549TWp3ojrvNr4DqQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScriptSherpa/DS-SEM5-PERSONA-OUTPUTS/blob/main/DS_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NIKHIL MALVI\n",
        "\n",
        "### Text Block: Model Evaluation in Multi-Class Classification\n",
        "\n",
        "In this code, we used the **Iris dataset**, a well-known dataset in machine learning, to train a **Logistic Regression** model for multi-class classification. Here's a breakdown of the process and results:\n",
        "\n",
        "1. **Data Preprocessing**:\n",
        "   - We loaded the dataset and selected two features, **'sepal length'** and **'sepal width'**, for simplicity.\n",
        "   - The dataset was split into training and testing sets (80% training, 20% testing).\n",
        "   - **Standardization** was performed on the features to ensure that all input features have a mean of 0 and a standard deviation of 1, which helps improve model performance.\n",
        "\n",
        "2. **Model Training**:\n",
        "   - We used a **Logistic Regression** model and trained it on the scaled training data (`X_train` and `y_train`).\n",
        "   - The model was trained for a maximum of 200 iterations.\n",
        "\n",
        "3. **Predictions and Performance Evaluation**:\n",
        "   - After training the model, we made predictions on the test data (`X_test`).\n",
        "   - We evaluated the model's performance using various metrics:\n",
        "     - **Confusion Matrix**: This 3x3 matrix shows the number of true positives, false positives, true negatives, and false negatives for each of the three classes (Iris-setosa, Iris-versicolor, Iris-virginica). It helps us understand how well the model performs for each class.\n",
        "     - **Accuracy**: This is the proportion of correct predictions to the total predictions, providing a simple measure of the model's performance.\n",
        "     - **Precision**: Measures the modelâ€™s ability to correctly predict positive instances of each class, taking into account the imbalance in the class distribution.\n",
        "     - **Recall**: Reflects how well the model identifies all actual instances of each class.\n",
        "     - **F1 Score**: The harmonic mean of precision and recall, providing a balance between them.\n",
        "\n",
        "4. **Evaluation Metrics Output**:\n",
        "   - **Accuracy**: Indicates the overall performance of the model.\n",
        "   - **Precision, Recall, and F1 Score**: These metrics are important when we care about both the correctness (precision) and completeness (recall) of the classification.\n",
        "\n",
        "# New Section"
      ],
      "metadata": {
        "id": "OgBouvmspImB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRiM94BepNvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ncX60X9rm8kS",
        "outputId": "cafba08c-0cff-4517-9362-1459eff6cbc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  7  2]\n",
            " [ 0  1 10]]\n",
            "Accuracy: 0.90\n",
            "Precision: 0.90\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the inbuilt Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Create DataFrame from the Iris dataset\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target  # Adding the target variable (species)\n",
        "\n",
        "# Preview the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Selecting features (X) and target variable (y)\n",
        "X = df[['sepal length (cm)', 'sepal width (cm)']]  # Using first two features for simplicity\n",
        "y = df['target']\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Compute accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    }
  ]
}